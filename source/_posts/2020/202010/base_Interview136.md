---
title: Interview_总结 (136)
date: 2020-10-12
tags: Interview
toc: true
---

### 面试题
    别看了 这就是你的题
    框架相关(1)

<!-- more -->

#### 分布式基本理论
- 微服务的发展

微服务倡导将复杂的单体应用拆分为若干个功能简单、松耦合的服务, 这样可以降低开发难度、增强扩展性、便于敏捷开发.当前被越来越多的开发者推崇, 很多互联网行业巨头、开源社区等都开始了微服务的讨论和实践.Hailo有160个不同服务构成, NetFlix有大约600个服务.国内方面, 阿里巴巴、腾讯、360、京东、58同城等很多互联网公司都进行了微服务化实践.当前微服务的开发框架也非常多, 比较著名的有Dubbo、SpringCloud、thrift 、grpc等.

- 微服务落地存在的问题

虽然微服务现在如火如荼, 但对其实践其实仍处于探索阶段.很多中小型互联网公司, 鉴于经验、技术实力等问题, 微服务落地比较困难.如著名架构师Chris Richardson所言, 目前存在的主要困难有如下几方面: 

1)单体应用拆分为分布式系统后, 进程间的通讯机制和故障处理措施变的更加复杂.

2)系统微服务化后, 一个看似简单的功能, 内部可能需要调用多个服务并操作多个数据库实现, 服务调用的分布式事务问题变的非常突出.

3)微服务数量众多, 其测试、部署、监控等都变的更加困难.

随着RPC框架的成熟, 第一个问题已经逐渐得到解决.例如dubbo可以支持多种通讯协议, springcloud可以非常好的支持restful调用.对于第三个问题, 随着docker、devops技术的发展以及各公有云paas平台自动化运维工具的推出, 微服务的测试、部署与运维会变得越来越容易.

而对于第二个问题, 现在还没有通用方案很好的解决微服务产生的事务问题.分布式事务已经成为微服务落地最大的阻碍, 也是最具挑战性的一个技术难题.微服务架构下, 分布式事务的各种解决方案, 并重点为大家解读阿里巴巴提出的分布式事务解决方案----GTS.该方案中提到的GTS是全新一代解决微服务问题的分布式事务互联网中间件.

- CAP理论

**一致性(Consistency)**: 分布式环境下多个节点的数据是否强一致.在分布式环境下, 一致性是指数据在多个副本之间能否保持一致的特性.在一致性的需求下, 当一个系统在数据一致的状态下执行更新操作后, 应该保证系统的数据仍然处于一直的状态.

对于一个将数据副本分布在不同分布式节点上的系统来说, 如果对第一个节点的数据进 行了更新操作并且更新成功后, 却没有使得第二个节点上的数据得到相应的更新, 于是在对第二个节点的数据进行读取操作时, 获取的依然是老数据(或称为脏数 据), 这就是典型的分布式数据不一致的情况.在分布式系统中, 如果能够做到针对一个数据项的更新操作执行成功后, 所有的用户都可以读取到其最新的值, 那么 这样的系统就被认为具有强一致性.

***分布式一致性的提出***

在分布式系统中要解决的一个重要问题就是数据的复制.在我们的日常开发经验中, 相 信很多开发人员都遇到过这样的问题: 假设客户端C1将系统中的一个值K由V1更新为V2, 但客户端C2无法立即读取到K的最新值, 需要在一段时间之后才能 读取到.这很正常, 因为数据库复制之间存在延时.

分布式系统对于数据的复制需求一般都来自于以下两个原因: 

1, 为了增加系统的可用性, 以防止单点故障引起的系统不可用

2, 提高系统的整体性能, 通过负载均衡技术, 能够让分布在不同地方的数据副本都能够为用户提供服务

数据复制在可用性和性能方面给分布式系统带来的巨大好处是不言而喻的, 然而数据复制所带来的一致性挑战, 也是每一个系统研发人员不得不面对的.

所谓分布一致性问题, 是指在分布式环境中引入数据复制机制之后, 不同数据节点之间 可能出现的, 并无法依靠计算机应用程序自身解决的数据不一致的情况.简单讲, 数据一致性就是指在对一个副本数据进行更新的时候, 必须确保也能够更新其他的副本, 否则不同副本之间的数据将不一致.

那么如何解决这个问题？一种思路是"既然是由于延时动作引起的问题, 那我可以将写入的动作阻塞, 直到数据复制完成后, 才完成写入动作". 没错, 这似乎能解决问题, 而且有一些系统的架构也确实直接使用了这个思路.但这个思路在解决一致性问题的同时, 又带来了新的问题: 写入的性能.如果你的应 用场景有非常多的写请求, 那么使用这个思路之后, 后续的写请求都将会阻塞在前一个请求的写操作上, 导致系统整体性能急剧下降.

总得来说, 我们无法找到一种能够满足分布式系统所有系统属性的分布式一致性解决方案.因此, 如何既保证数据的一致性, 同时又不影响系统运行的性能, 是每一个分布式系统都需要重点考虑和权衡的.于是, 一致性级别由此诞生: 

数据的一致性模型可以分成以下 3 类: 

***强一致性***: 数据更新成功后, 任意时刻所有副本中的数据都是一致的, 一般采用同步的方式实现.

***弱一致性***: 数据更新成功后, 系统不承诺立即可以读到最新写入的值, 也不承诺具体多久之后可以读到.

***最终一致性***: 弱一致性的一种形式, 数据更新成功后, 系统不承诺立即可以返回最新写入的值, 但是保证最终会返回上一次更新操作的值.这里之所以将最终一致性单独提出来, 是因为它是弱一致性中非常推崇的一种一致性模型, 也是业界在大型分布式系统的数据一致性上比较推崇的模型.

**可用性(Availability)**: 可用性是指系统提供的服务必须一直处于可用的状态, 对于用户的每一个操作请求总是能够在有限的时间内返回结果.这里的重点是"有限时间内"和"返回结果".

"有限时间内"是指, 对于用户的一个操作请求, 系统必须能够在指定的时间内返回对应的处理结果, 如果超过了这个时间范围, 那么系统就被认为是不可用的.另外, "有限的时间内"是指系统设计之初就设计好的运行指标, 通常不同系统之间有很大的不同, 无论如何, 对于用户请求, 系统必须存在一个合理的响应时间, 否则用户便会对系统感到失望.

"返回结果"是可用性的另一个非常重要的指标, 它要求系统在完成对用户请求的处理后, 返回一个正常的响应结果.正常的响应结果通常能够明确地反映出队请求的处理结果, 即成功或失败, 而不是一个让用户感到困惑的返回结果.

用户可以选择向 G1 或 G2 发起读操作.不管是哪台服务器, 只要收到请求, 就必须告诉用户, 到底是 v0 还是 v1, 否则就不满足可用性.

**分区容错性(Partition Tolerance)**: 分区容错性约束了一个分布式系统具有如下特性: 分布式系统在遇到任何网络分区故障的时候, 仍然需要能够保证对外提供满足一致性和可用性的服务, 除非是整个网络环境都发生了故障.

网络分区是指在分布式系统中, 不同的节点分布在不同的子网络(机房或异地网络) 中, 由于一些特殊的原因导致这些子网络出现网络不连通的状况, 但各个子网络的内部网络是正常的, 从而导致整个系统的网络环境被切分成了若干个孤立的区域. 需要注意的是, 组成一个分布式系统的每个节点的加入与退出都可以看作是一个特殊的网络分区.

大多数分布式系统都分布在多个子网络.每个子网络就叫做一个区(partition).分区容错的意思是, 区间通信可能失败.比如, 一台服务器放在中国, 另一台服务器放在美国, 这就是两个区, 它们之间可能无法通信.

- BASE 理论

BASE理论是对CAP中一致性和可用性权衡的结果, 其来源于对大规模互联网系统分布式实践的总结,  是基于CAP定理逐步演化而来的.BASE理论的核心思想是: 即使无法做到强一致性, 但每个应用都可以根据自身业务特点, 采用适当的方式来使系统达到最终一致性.接下来看一下BASE中的三要素: 

基本可用(BasicallyAvailable): 指分布式系统在出现故障时, 允许损失部分的可用性来保证核心可用, 注意, 这绝不等价于系统不可用.比如: 

           ** 响应时间上的损失.正常情况下, 一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果, 但由于出现故障, 查询结果的响应时间增加了1~2秒

          ** 系统功能上的损失: 正常情况下, 在一个电子商务网站上进行购物的时候, 消费者几乎能够顺利完成每一笔订单, 但是在一些节日大促购物高峰的时候, 由于消费者的购物行为激增, 为了保护购物系统的稳定性, 部分消费者可能会被引导到一个降级页面

软状态(SoftState): 指允许分布式系统存在中间状态, 该中间状态不会影响到系统的整体可用性, 即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时.

最终一致性(EventualConsistency): 指分布式系统中的所有副本数据经过一定时间后, 最终能够达到一致的状态, 因此, 最终一致性的本质是需要系统保证最终数据能够达到一致, 而不需要实时保证系统数据的强一致性.

总的来说, BASE理论面向的是大型高可用可扩展的分布式系统, 和传统的事物ACID特性是相反的, 它完全不同于ACID的强一致性模型, 而是通过牺牲强一致性来获得可用性, 并允许数据在一段时间内是不一致的, 但最终达到一致状态.但同时, 在实际的分布式场景中, 不同业务单元和组件对数据一致性的要求是不同的, 因此在具体的分布式系统架构设计过程中, ACID特性和BASE理论往往又会结合在一起.

