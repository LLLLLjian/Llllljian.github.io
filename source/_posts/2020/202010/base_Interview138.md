---
title: Interview_总结 (138)
date: 2020-10-14
tags: Interview
toc: true
---

### 面试题
    别看了 这就是你的题
    框架相关(4)

<!-- more -->

#### 分布式缓存

缓存技术是一个老生常谈的问题, 但是它也是解决性能问题的利器, 一把瑞士军刀；而且在各种面试过程中或多或少会被问及一些缓存相关的问题, 如缓存算法、热点数据与更新缓存、更新缓存与原子性、缓存崩溃与快速恢复等各种与缓存相关的问题.而这些问题中有些问题又是与场景相关, 因此如何合理应用缓存来解决问题也是一个选择题.

- 多级缓存介绍
    * 所谓多级缓存, 即在整个系统架构的不同系统层级进行数据缓存, 以提升访问效率, 这也是应用最广的方案之一
    ![多级缓存](/img/20201013_1.png)
    * 首先接入Nginx将请求负载均衡到应用Nginx, 此处常用的负载均衡算法是轮询或者一致性哈希, 轮询可以使服务器的请求更加均衡, 而一致性哈希可以提升应用Nginx的缓存命中率
    * 接着应用Nginx读取本地缓存(本地缓存可以使用Lua Shared Dict、Nginx Proxy Cache(磁盘/内存)、Local Redis实现), 如果本地缓存命中则直接返回, 使用应用Nginx本地缓存可以提升整体的吞吐量, 降低后端的压力, 尤其应对热点问题非常有效
    * 如果Nginx本地缓存没命中, 则会读取相应的分布式缓存(如Redis缓存, 另外可以考虑使用主从架构来提升性能和吞吐量), 如果分布式缓存命中则直接返回相应数据(并回写到Nginx本地缓存)
    * 如果分布式缓存也没有命中, 则会回源到Tomcat集群, 在回源到Tomcat集群时也可以使用轮询和一致性哈希作为负载均衡算法
    * 在Tomcat应用中, 首先读取本地堆缓存, 如果有则直接返回(并会写到主Redis集群
    * 作为可选部分, 如果步骤4没有命中可以再尝试一次读主Redis集群操作, 目的是防止当从有问题时的流量冲击
    * 如果所有缓存都没有命中只能查询DB或相关服务获取相关数据并返回
    * 步骤7返回的数据异步写到主Redis集群, 此处可能多个Tomcat实例同时写主Redis集群, 可能造成数据错乱
- 如何缓存数据
    * 过期与不过期
        ![缓存一般场景](/img/20201014_1.png)
        * 可能存在的问题
            * 事务在提交时失败则写缓存是不会回滚的造成DB和缓存数据不一致；
            * 假设多个人并发写缓存可能出现脏数据的；
            * 同步写对性能有一定的影响, 异步写存在丢数据的风险.
        ![缓存升级版](/img/20201014_2.png)
        * 图解
            * 把写缓存改成写消息, 通过消息通知数据变更；
            * 同步缓存系统会订阅消息, 并根据消息进行更新缓存；
            * 数据一致性可以采用: 消息体只包括ID、然后查库获取最新版本数据；通过时间戳和内容摘要机制(MD5)进行缓存更新；
            * 如上方法也不能保证消息不丢失, 可以采用: 应用在本地记录更新日志, 当消息丢失了回放更新日志；或者采用数据库binlog, 采用如canal订阅binlog进行缓存更新.
    * 维度化缓存与增量缓存
        * 对于电商系统, 一个商品可能拆成如: 基础属性、图片列表、上下架、规格参数、商品介绍等；如果商品变更了要把这些数据都更新一遍那么整个更新成本很高: 接口调用量和带宽；因此最好将数据进行维度化并增量更新(只更新变的部分).尤其如上下架这种只是一个状态变更, 但是每天频繁调用的, 维度化后能减少服务很大的压力.
- 分布式缓存与应用负载均衡
    * 缓存分布式: 一般采用分片实现, 即将数据分散到多个实例或多台服务器.算法一般采用取模和一致性哈希
    * 应用负载均衡
        * 轮询的优点: 到应用Nginx的请求更加均匀, 使得每个服务器的负载基本均衡；
        * 轮询的缺点: 随着应用Nginx服务器的增加, 缓存的命中率会下降, 比如原来10台服务器命中率为90%, 再加10台服务器将可能降低到45%；而这种方式不会因为热点问题导致其中某一台服务器负载过重.
        * 一致性哈希的优点: 相同请求都会转发到同一台服务器, 命中率不会因为增加服务器而降低
        * 一致性哈希的缺点: 因为相同的请求会转发到同一台服务器, 因此可能造成某台服务器负载过重, 甚至因为请求太多导致服务出现问题.
        * 负载较低时使用一致性哈希
        * 热点请求降级一致性哈希为轮询
        * 将热点数据推送到接入层Nginx, 直接响应给用户
- 更新缓存与原子性
    * 更新数据时使用更新时间戳或者版本对比, 如果使用Redis可以利用其单线程机制进行原子化更新
    * 使用如canal订阅数据库binlog
    * 将更新请求按照相应的规则分散到多个队列, 然后每个队列的进行单线程更新, 更新时拉取最新的数据保存
    * 分布式锁, 更新之前获取相关的锁

#### 一致性Hash算法
> 都学到这了, 就再看看一致性Hash算法吧
- 引子
    * 假设我们有一个网站, 最近发现随着流量增加, 服务器压力越来越大, 之前直接读写数据库的方式不太给力了, 于是我们想引入Redis作为缓存机制.现在我们一共有三台机器可以作为Redis服务器,如下图所示
    ![一致性Hash算法引子](/img/20201014_3.png)
- 要解决的问题
    * 一般来说我们在大规模访问, 大并发流量下都会使用到分布式缓存, 即将廉价机器部署在同一个子网内, 形成多机器集群, 然后通过负载均衡以及一定的路由规则进行读请求的分流, 将请求映射到对应的缓存服务器上.如何对请求与缓存服务器之间进行精准映射,以及优雅的扩展, 剔除缓存服务器是分布式缓存部署的痛点.
- 传统做法
    * 随机选取: 将每一次Redis请求随机发送到一台Redis服务器.
    * 产生的问题
        * 同一份数据可能被存在不同的机器上而造成数据冗余
        * 有可能某数据已经被缓存但是访问却没有命中, 因为无法保证对相同key的所有访问都被发送到相同的服务器
    * 计算哈希: 保证相同key每次访问同一台Redis服务器
    * 产生的问题
        * 容错性(指当系统中某一个或几个服务器变得不可用时, 整个系统是否可以正确高效运行)低
        * 扩展性(指当加入新的服务器后, 整个系统是否可以正确高效运行)也低
- 解决方案: 一致性哈希算法
    * 一致性哈希将整个哈希值空间组织成一个虚拟的圆环, 如假设某哈希函数H的值空间为0 – 2^32-1(即哈希值是一个32位无符号整形), 整个空间按顺时针方向组织.0和2^32-1在零点中方向重合.下一步将各个服务器使用H进行一个哈希, 具体可以选择服务器的ip或主机名作为关键字进行哈希, 这样每台机器就能确定其在哈希环上的位置
    * 接下来使用如下算法定位数据访问到相应服务器: 将数据key使用相同的函数H计算出哈希值h, 通根据h确定此数据在环上的位置, 从此位置沿环顺时针“行走”, 第一台遇到的服务器就是其应该定位到的服务器.
    * 例如我们缓存服务器中有A、B、C、D四个key对应的数据对象, 经过哈希计算后, 在环空间上的位置如下: 
    ![一致性Hash算法](/img/20201014_4.png)
    * 假设redis2宕机了, 可以看到ACD节点并不受影响, 只有B节点被重定向至Redis-0
    ![一致性Hash算法](/img/20201014_5.png)
    * 假设添加一个机器redis3, 只有C这个key重新定位到redis3, 其他的均不发生变化
    ![一致性Hash算法](/img/20201014_6.png)
- 可能遇到的问题: 数据侵斜
    * 一致性哈希算法在服务节点太少时, 容易因为节点分部不均匀而造成数据倾斜问题.例如我们的系统中有两台服务器, 其环分布如下, 此时必然造成大量数据集中到Redis-1上, 而只有极少量会定位到Redis-0上
    ![一致性Hash算法](/img/20201014_7.png)
- 解决数据侵斜的方法: 虚拟节点
    * 为了解决这种数据倾斜问题, 一致性哈希算法引入了虚拟节点机制, 即对每一个服务节点计算多个哈希, 每个计算结果位置都放置一个此服务节点, 称为虚拟节点.具体做法可以在服务器ip或主机名的后面增加编号来实现.例如上面的情况, 我们决定为每台服务器计算三个虚拟节点, 于是可以分别计算“Redis-1 #1”、“Redis-1 #2”、“Redis-1 #3”、“Redis-0 #1”、“Redis-0 #2”、“Redis-0 #3”的哈希值, 于是形成六个虚拟节点: 
    ![一致性Hash算法](/img/20201014_8.png)
    * 时数据定位算法不变, 只是多了一步虚拟节点到实际节点的映射, 例如定位到“Redis-1#1”、“Redis-1#2”、“Redis-1#3”三个虚拟节点的数据均定位到Redis-1上.这样就解决了服务节点少时数据倾斜的问题.在实际应用中, 通常将虚拟节点数设置为32甚至更大, 因此即使很少的服务节点也能做到相对均匀的数据分布.


