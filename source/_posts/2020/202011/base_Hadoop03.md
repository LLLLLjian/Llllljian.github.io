---
title: Hadoop_基础 (03)
date: 2020-11-25
tags: Hadoop
toc: true
---

### 快来跟我一起学HDFS
    还需要学一下大数据
    先看看Hadoop

<!-- more -->

#### NameNode
- 功能
    * 接受客户端的读写信息
    * 保存文件的时候会保存文件的元数据信息
        * 文件的归属
        * 文件的权限
        * 文件的大小时间
        * Block信息, 但Block的位置信息不会持久化 需要每次启动的时候由DN上报
    * 收集Block的位置信息
        * 系统启动
            * NN关机的时候是不会存储任何的Block与DN的映射信息
            * DN启动的时候，会将自己节点上储存的Block信息汇报给NN
            * NN接受请求之后重新生成映射信息
                * File->Block
                * Block->DN
            * 如果某个数据块的副本数小于设置数, 那么NN会将这个副本拷贝至其他节点
        * 集群运行中
            * NN与DN保持心跳机制, 三秒钟发送一次
            * 如果客户端需要读取或上传数据的时候, NN需要知道DN的健康状况
            * 可以让客户端读取存活的DN节点
            * 如果DN超过三秒没有心跳, 就认为DN出现异常, 就不会让新的数据读写到DN
            * 如果DN超过10分钟没有心跳, 那么NN就会将当前DN存储的数据转移到其他节点
- NN为了效率将所有的操作都在内存中完成
    * 执行速度快
    * NN不会和磁盘进行任何数据交换
    * 数据保存在内存中, 断电易失

#### DataNode
- 存放的是文件的数据信息
- 数据会存放在硬盘上
- 汇报
    * 启动时
        * 向NN汇报当前DN上的Block的信息
    * 运行中
        * 向NN保持心跳机制

#### SecondaryNameNode
- 传统的内存持久化方案
    * 日志机制
        * 做任何操作之前都先记录日志
        * 数据文件大小不可控, 随着时间的发展 集群启动的时间会越来越长
    * 拍摄快照
        * 我们可以将内存中的数据写到硬盘上: 序列化
        * 启动时还可以将硬盘上的数据写回内存中: 反序列化
        * 缺点1: 关机时间长
        * 缺点2: 如果是异常关机, 数据还在内存中 没法写入磁盘
        * 缺点3: 如果写出频率过高， 导致内存使用率低
- SSN解决方案
    * 解决思路
        * 让日志大小可控
        * 快照需要定时存储
        * 日志+快照
    * 解决方案
        * 每次集群启动的时候都会生成一个fsimage
        * 每次操作都会记录一个edit_log
        * 随着时间的推移, 日志文件会越来越大 达到阀值(64M或者3600秒)的时候会生成新的日志文件


